{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dbefd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "#The dataset consists of people who have donated their voice online. \n",
    "#You agree to not attempt to determine the identity of speakers in the Common Voice dataset.\n",
    "dataset = load_dataset(\"common_voice\", \"zh-HK\", split='validated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#references https://github.com/scottykwok/cantonese-selfish-project/blob/master/Part4_wav2vec2/Run_wav2vec2_Cantonese.ipynb\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from functools import lru_cache\n",
    "\n",
    "# load pretrained model\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"scottykwok/wav2vec2-large-xlsr-cantonese\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"scottykwok/wav2vec2-large-xlsr-cantonese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88633cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pandas dataframe of commonvoice validated dataset\n",
    "df = pd.DataFrame(columns=['path','sentence','results'])\n",
    "df['path']=dataset['path']\n",
    "df['sentence']=dataset['sentence']\n",
    "df=df[df.sentence.apply(lambda x:len(str(x))>8)]#filter sentence length>8\n",
    "df.reset_index()\n",
    "df.drop(columns='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2d7e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.head()\n",
    "\n",
    "#change audio sample rate to 16000\n",
    "@lru_cache(maxsize=None)\n",
    "def resampler(rate):\n",
    "    return torchaudio.transforms.Resample(rate,16000)\n",
    "\n",
    "predictions=[]\n",
    "#run model on audio\n",
    "for path,sentence in zip(df['path'],df['sentence']):\n",
    "    \n",
    "    #attempt on loading mp3 with windows\n",
    "    #audio = AudioSegment.from_mp3('zh-HK/clips/'+path)\n",
    "    #temp=a.get_array_of_samples()\n",
    "    #sample_rate=a.framerate\n",
    "    #audio_input=np.array(y)[::2]\n",
    "    #audio_input=audio_input.astype('float32')/10000\n",
    "    #y-=y.mean()\n",
    "    \n",
    "    audio_input, sample_rate=torchaudio.load(path)\n",
    "    transform=resampler(sample_rate)\n",
    "    audio_input=transform(audio_input)\n",
    "    \n",
    "    # pad input values and return pt tensor\n",
    "    input_values = processor(audio_input, sampling_rate=16000, return_tensors=\"pt\").input_values\n",
    "    \n",
    "    # INFERENCE\n",
    "    # retrieve logits & take argmax\n",
    "    logits = model(input_values).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    # transcribe\n",
    "    predictions.append(processor.decode(predicted_ids[0]))\n",
    "df['results']=predictions\n",
    "df.drop(columns='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e644f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternate code to test if the result-saving works\n",
    "df=df.head()\n",
    "predictions=list(df['sentence'])\n",
    "df['results']=predictions\n",
    "df.drop(columns='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e922e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tested.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cantoproject",
   "language": "python",
   "name": "cantoproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
