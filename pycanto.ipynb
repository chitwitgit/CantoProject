{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c99ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "216990e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycantonese as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db6244f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.獅子山下體現香港精神\n",
      " | 獅子山下 | 體現 | 香港 | 精神 | \n",
      "2.挪威農民餓死逾四百隻豬判囚一年\n",
      " | 挪威 | 農民 | 餓死 | 逾 | 四百 | 隻 | 豬 | 判 | 囚 | 一年 | \n",
      "3.我覺得呢個人相當有嫌疑\n",
      " | 我 | 覺得 | 呢個 | 人相 | 當 | 有 | 嫌疑 | \n",
      "4.打波先嚟落雨，唔通連個天都唔鍾意我\n",
      " | 打波 | 先嚟 | 落雨 | ， | 唔通 | 連 | 個 | 天 | 都 | 唔 | 鍾意 | 我 | \n",
      "5.生命有希望，行路比車撞\n",
      " | 生命 | 有希望 | ， | 行路 | 比 | 車 | 撞 | \n",
      "6.這些機會不是屬於我們的\n",
      " | 這些 | 機會 | 不是 | 屬於 | 我們 | 的 | \n"
     ]
    }
   ],
   "source": [
    "#test pycantonese\n",
    "examples = [\n",
    "    \"獅子山下體現香港精神\",\n",
    "    \"挪威農民餓死逾四百隻豬判囚一年\",\n",
    "    \"我覺得呢個人相當有嫌疑\",\n",
    "    \"打波先嚟落雨，唔通連個天都唔鍾意我\",\n",
    "    \"生命有希望，行路比車撞\",\n",
    "    \"這些機會不是屬於我們的\"\n",
    "]\n",
    "for n, i in enumerate(examples):\n",
    "    print(f'{n + 1}.{i}')\n",
    "    segmentedstr = ' | '\n",
    "    for w in pc.segment(i):\n",
    "        segmentedstr+=w+' | '\n",
    "    print(segmentedstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dec0c74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/gp/6pp66rr92wl7bwzv14mx_xmc0000gn/T/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.獅子山下體現香港精神\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.443 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | 獅子 | 山下 | 體現 | 香港 | 精神 | \n",
      "2.挪威農民餓死逾四百隻豬判囚一年\n",
      " | 挪威 | 農民餓 | 死 | 逾 | 四百 | 隻 | 豬判囚 | 一年 | \n",
      "3.我覺得呢個人相當有嫌疑\n",
      " | 我覺 | 得 | 呢 | 個 | 人 | 相當 | 有 | 嫌疑 | \n",
      "4.打波先嚟落雨，唔通連個天都唔鍾意我\n",
      " | 打波 | 先 | 嚟 | 落雨 | ， | 唔 | 通連個 | 天 | 都 | 唔 | 鍾 | 意 | 我 | \n",
      "5.生命有希望，行路比車撞\n",
      " | 生命 | 有 | 希望 | ， | 行路 | 比車 | 撞 | \n",
      "6.這些機會不是屬於我們的\n",
      " | 這些 | 機會 | 不是 | 屬 | 於 | 我們 | 的 | \n"
     ]
    }
   ],
   "source": [
    "#test vanilla jieba\n",
    "import jieba\n",
    "for n,i in enumerate(examples):\n",
    "    print(f'{n+1}.{i}')\n",
    "    segmentedstr = ' | '\n",
    "    for w in jieba.cut(i):\n",
    "        segmentedstr+=w+' | '\n",
    "    print(segmentedstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1d90b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd72c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wget(url, encoding = 'utf8'): \n",
    "    r=requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    return r.content.decode(encoding)\n",
    "def download_word_frequency():\n",
    "    data=wget(url='https://words.hk/faiman/analysis/existingwordcount.json')\n",
    "    return pd.DataFrame(json.loads(data),index=['count']).transpose() \\\n",
    "                .sort_values(by='count',ascending=False)\n",
    "def save_word_frequency(df, filename):\n",
    "    with open(filename,\"w\") as file:\n",
    "        for word,row in df.iterrows():\n",
    "            if len(word) > 1:\n",
    "                file.write(f'{word.replace(\"*\",\"\")} {row[\"count\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db24a05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.獅子山下體現香港精神\n",
      " | 獅子山 | 下 | 體現 | 香港 | 精神 | \n",
      "2.挪威農民餓死逾四百隻豬判囚一年\n",
      " | 挪威 | 農民 | 餓 | 死 | 逾 | 四百 | 隻 | 豬判囚 | 一年 | \n",
      "3.我覺得呢個人相當有嫌疑\n",
      " | 我 | 覺得 | 呢個 | 人 | 相當 | 有 | 嫌疑 | \n",
      "4.打波先嚟落雨，唔通連個天都唔鍾意我\n",
      " | 打波 | 先 | 嚟 | 落雨 | ， | 唔通 | 連個 | 天 | 都 | 唔 | 鍾意 | 我 | \n",
      "5.生命有希望，行路比車撞\n",
      " | 生命 | 有 | 希望 | ， | 行路 | 比車 | 撞 | \n",
      "6.這些機會不是屬於我們的\n",
      " | 這些 | 機會 | 不是 | 屬於 | 我們 | 的 | \n"
     ]
    }
   ],
   "source": [
    "#testing jieba+粵典\n",
    "save_word_frequency(download_word_frequency(), \"粵典_userdict.txt\")\n",
    "jieba.load_userdict(\"粵典_userdict.txt\")\n",
    "for n,i in enumerate(examples):\n",
    "    print(f'{n+1}.{i}')\n",
    "    segmentedstr = ' | '\n",
    "    for w in jieba.cut(i):\n",
    "        segmentedstr+=w+' | '\n",
    "    print(segmentedstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "095abf53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.獅子山下體現香港精神\n",
      " | 獅子山下 | 體現 | 香港 | 精神 | \n",
      "2.挪威農民餓死逾四百隻豬判囚一年\n",
      " | 挪威 | 農民 | 餓死 | 逾 | 四百 | 隻 | 豬 | 判 | 囚 | 一年 | \n",
      "3.我覺得呢個人相當有嫌疑\n",
      " | 我 | 覺得 | 呢個 | 人相 | 當 | 有 | 嫌疑 | \n",
      "4.打波先嚟落雨，唔通連個天都唔鍾意我\n",
      " | 打波 | 先嚟 | 落雨 | ， | 唔通 | 連 | 個 | 天 | 都 | 唔 | 鍾意 | 我 | \n",
      "5.生命有希望，行路比車撞\n",
      " | 生命 | 有希望 | ， | 行路 | 比 | 車 | 撞 | \n",
      "6.這些機會不是屬於我們的\n",
      " | 這些 | 機會 | 不是 | 屬於 | 我們 | 的 | \n"
     ]
    }
   ],
   "source": [
    "#testing pycantonese+粵典 \n",
    "from pycantonese.word_segmentation import Segmenter\n",
    "with open(\"粵典_userdict.txt\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "words,freq=zip(*[i.split() for i in lines])\n",
    "segmenter=Segmenter(allow=set(words))\n",
    "for n,i in enumerate(examples):\n",
    "    print(f'{n + 1}.{i}')\n",
    "    segmentedstr = ' | '\n",
    "    for w in pc.segment(i,cls=segmenter):\n",
    "        segmentedstr+=w+' | '\n",
    "    print(segmentedstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07e0d316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我', '覺得', '呢個', '人', '相當', '有', '嫌疑']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#customising pycantonese\n",
    "from pycantonese.word_segmentation import Segmenter\n",
    "with open(\"粵典_userdict.txt\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "words=[i.split()[0] for i in lines]\n",
    "segmenter=Segmenter(disallow={'人相'})\n",
    "pc.segment(\"我覺得呢個人相當有嫌疑\", cls=segmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5d4a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#references https://github.com/scottykwok/cantonese-selfish-project/blob/master/Part3_PyCantonese_Jieba/%E4%B8%AD%E6%96%87%E5%88%86%E8%A9%9E.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
